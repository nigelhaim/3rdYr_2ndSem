
Deep Neural Network Object localization has gained success in different researches. It has considered as a requirement before other methods used for medical image analysis. The objective of localization is focused on detecting specific region of interest (ROI) in medical images(Alaskar et al., 2022). The ROI strategy is to exclude the effects of unnecessary tissues in the MRI to enhance segmentation accuracy (Li et al., 2022)

**Localized Region Contrast**

One of the approaches in using localized regions in MRI images is through the proposal of Yan et al. (2023). Their proposal is applying the idea of Contrastive learning frameworks to be integrated to Localized region. The approach is identifying Super-pixels through Felzenszwalb's algorithm and performs contrastive learning. They enhanced the algorithm that differentiates local regions and formulate the positive and negative pairs. Then perform elastic transformation for both the image and its corresponding local regions to form an augmented image. During implementation all images are re-sampled to have a spacing of 2.5 mm x 1.0 mm x 1.00 mm with respect to the 3D volume's depth, height, and width. Yan et al. (2023) used SGD optimized to pre-train a ResNet-50 encoder for 200 epochs in the global contrast. The whole framework of the local contrast was trained by Adam optimized in an end-to-end fashion. 

![[Pasted image 20240413132039.png]]
Fig. 1. The first 3 pictures are generated by Felzenszwalb's algorithm and the embeddings from the local contrast model clustered through K-Means on the right

The results shows significant improvement, on different datasets. The experiments consistently show LRC boosts the multi-organ segmentation performance of most global contrast model across all three datasets (Yan et al., 2023). They also visualized in Figure 1 that is generated by the Felzenswalb's algorithm and the features from the LRC. The results demonstrated that LRC learns informative semantic features that can be effectively clustered using a simple K-Means algorithm (Yan et al., 2023). The study concluded that Localized Region Contrasts provides a direction in accurately medical image segmentation improvements. 

**T2*-weighted MRI Microbleed detection***

A study conducted by Anthony et al. (2021) on applying localization that automatically detects microbleeds in T2*-weighted MRI data. They demonstrated the detection of CMB over cross-sectional and longitudinal scans ideally for large-scale studies. The algorithm identifies CMB through the anatomical localization on brain atlases. 

Their data consists of T1-weighted images, T2*-weighted  SWI, and T2*-weighted GRE Magnetic resonance images with T1-wighted and T2*-weighted images uses the same parameters. The data was visually inspected and determined the microbleeds and its location by three raters (IBM with over eight years of experience, EA and AGC with two years of experience). Fleiss' kappa was used for interrater and intra-rater for the assessment of microbleeds (Anthony et al., 2021). 

The data was preprocessed by extracting the brain through FSL Brain Extraction Toolbox of the SWI and GRE T2*-weighted MRI scans. The FSL's MNI lobar mask and T1-weighted images were co-registered to both SWI and GRE images. The CSF mask using the Statistical Parametric Mapping toolbox was used to compute the CSF mask through the co-registered T1-weighted volume. The SWI and GRE scans are then resampled to a higher resolution to a factor of three. Microbleed artifacts would have a diameter at least six voxels (Anthony et al., 2021). 

The identification of circular regions of interests of potential microbleeds was done on computing each slice of the GRE or SWI image with a 3 x 3 Sobel filter. The edge pixels were then detected through Canny edge detection algorithm to remove all neighboring voxels that are not local maxima. To remove spurious edges, hysteresis thresholding was used. Hough transform is an algorithm that focuses in lenient definition of circularity which allows to be more sensitive to ovoid shapes. The algorithm with a lenient threshold of 80% of the maximum overlap was then used in detecting the regions of interest on all corresponding slices. 

The preprocessing methods significantly reduced the potential locations of Microbleed. The remaining overlapping regions of interests were merged together are to large to be true microbleeds. These potential microbleeds are excluded and considered as vessels since the lenient cutoff distance between centers greater than eight pixels (1.15 mm). This method is similar to the visual rating criteria. Finally the region that represents the microbleed candidate was defined as the 3D center and a surrounding neighborhood of a standardized size of 51 x 51 x 25 voxels (two times the maximum expected size of a microbleed). It was used since the neighborhood of this size ensures the candidate is passed for analysis. 

Furthermore to remove false positive locations Anthony et al. (2021) used geometric information contained in the Regions of interest. The 3D image entropy, the 2D image entropy of the maximum intensity projection of the ROI and the volume and compactness of the central blob in each ROI as identified through the Frangi filtering.  


Alaskar, H., Hussain, A., Almaslukh, B., Vaiyapuri, T., Sbai, Z., & Dubey, A. K. (2022). Deep learning approaches for automatic localization in medical images. _Computational Intelligence and Neuroscience_, _2022_, 6347307. https://doi.org/10.1155/2022/6347307

Li, S., Liu, J., & Song, Z. (2022). Brain tumor segmentation based on region of interest-aided localization and segmentation U-Net. _International Journal of Machine Learning and Cybernetics_, _13_(9), 2435–2445. https://doi.org/10.1007/s13042-022-01536-4


>[!Note]- Definition of Terms
>Localization
>Region of Interests (ROI)
>Segmentation
>Contrastive learning
> Super-pixels 
> Felzenszwalb's algorithm
> Elastic transformation
> Image Augmentation
> Semantic Features
> Longitudinal scans
> Brain Atlas
> Hough transform
> Frangi filtering

>[!Note]- Dumps 
>Through the input image $x_q$ and its transform $x_p$ the positive and negative pairs for local contrast are generated. For every input image $x$ the algorithm provides $K$ local regions $R$ = {$r^1, r^2,...,r^K$} where $r^k$ where $k$ is the local region cluster for the image. They performed elastic transform to generate an augmented image $x_p = T_e(x_q)$ based from the query image $x_q$ and its local regions $R_q$. They then used U-Net 




